{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34be011f-a3ff-49b5-9c46-f80b77a48219",
   "metadata": {},
   "source": [
    "The aim is to implement a NLP process upon historical data to make previsions upon new data\n",
    "\n",
    "Differences between NLP and LLM : \n",
    "| Aspect               | **NLP (Natural Language Processing)**                                                                       | **LLM (Large Language Model)**                                                                                            |\n",
    "| -------------------- | ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Définition**       | Discipline de l’IA qui traite le langage humain (textes/parole).                                            | Type de modèle basé sur le deep learning, entraîné sur de très grands corpus de textes.                                   |\n",
    "| **Rôle**             | Champ global : comprend toutes les méthodes (règles, statistiques, ML, deep learning).                      | Un outil moderne et puissant qui fait partie du NLP.                                                                      |\n",
    "| **Méthodes**         | - Règles linguistiques<br>- Bag of Words<br>- TF-IDF<br>- Word2Vec<br>- BERT                                | - GPT (OpenAI)<br>- LLaMA (Meta)<br>- Mistral<br>- Falcon                                                                 |\n",
    "| **Tâches typiques**  | - Classification de textes<br>- Analyse de sentiments<br>- Résumé<br>- Traduction<br>- Extraction d’entités | - Génération de texte cohérent<br>- Chatbots (conversation)<br>- Raisonnement complexe<br>- Few-shot / Zero-shot learning |\n",
    "| **Taille / Données** | Petits à moyens corpus, souvent spécialisés.                                                                | Trillions de tokens, milliards de paramètres.                                                                             |\n",
    "| **Limites**          | Dépend beaucoup des features manuelles et de tâches spécifiques.                                            | Très coûteux à entraîner, peut \"halluciner\", opaque.                                                                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb9e2e9-701f-4001-8bfc-63456d873092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('IMDB_train_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e919063f-9749-4f99-b94a-d7c9006d65ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60 background rehears record sympathi devil cl...</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tess storm countri mari pickford vehicl intend...</td>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well suppos good news concern william winckler...</td>\n",
       "      <td>1140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somewher read film suppos comedi see call anyt...</td>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man hilari comedi stupid made realiz pile stan...</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  polarity\n",
       "0  60 background rehears record sympathi devil cl...     653         0\n",
       "1  tess storm countri mari pickford vehicl intend...     998         1\n",
       "2  well suppos good news concern william winckler...    1140         0\n",
       "3  somewher read film suppos comedi see call anyt...     341         0\n",
       "4  man hilari comedi stupid made realiz pile stan...     367         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb6531b-4110-429b-aeba-012178ed38f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describ larri interview complet suckhol everi ...</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giorgino peopl look bit long one rare real rom...</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movi amaz never seen film brought harsh realit...</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one anim film animatrix collect one nine one d...</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juli andrew satir prod goodi two shoe imag ove...</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  polarity\n",
       "0  describ larri interview complet suckhol everi ...     458         0\n",
       "1  giorgino peopl look bit long one rare real rom...     113         1\n",
       "2  movi amaz never seen film brought harsh realit...     218         1\n",
       "3  one anim film animatrix collect one nine one d...     191         1\n",
       "4  juli andrew satir prod goodi two shoe imag ove...     713         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB_test_prepared.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cd32dd-8ef5-449d-a365-ae357c61c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "955fea19-0926-4746-a514-a211fc2a0fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Small model\n",
    "# Use the exclamation mark prefix to run shell commands in Jupyter notebooks\n",
    "!python -m spacy download fr_core_news_sm\n",
    "\n",
    "# Alternatively, you can use the system command from IPython\n",
    "import sys\n",
    "!{sys.executable} -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd2c79e-2b84-4a1e-9fba-33579531bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n",
      "Collecting fr-core-news-md==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "# Mean model\n",
    "# Use the exclamation mark prefix to run shell commands in Jupyter notebooks\n",
    "!python -m spacy download fr_core_news_md\n",
    "\n",
    "# Alternatively, you can use the system command from IPython\n",
    "import sys\n",
    "!{sys.executable} -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140410a8-fd22-49cb-8f24-dea31edfcae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.8.0/fr_core_news_lg-3.8.0-py3-none-any.whl (571.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_lg')\n",
      "Collecting fr-core-news-lg==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.8.0/fr_core_news_lg-3.8.0-py3-none-any.whl (571.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "# Large model\n",
    "# Use the exclamation mark prefix to run shell commands in Jupyter notebooks\n",
    "!python -m spacy download fr_core_news_lg\n",
    "\n",
    "# Alternatively, you can use the system command from IPython\n",
    "import sys\n",
    "!{sys.executable} -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae11c75-6885-4125-955c-84c6bbfcc399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60 background rehears record sympathi devil cl...</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>background rehear record sympathi devil classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tess storm countri mari pickford vehicl intend...</td>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>tess storm countri mari pickford vehicl intend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well suppos good news concern william winckler...</td>\n",
       "      <td>1140</td>\n",
       "      <td>0</td>\n",
       "      <td>well suppos good news concern william winckler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somewher read film suppos comedi see call anyt...</td>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "      <td>somewher read film suppos comedi see call anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man hilari comedi stupid made realiz pile stan...</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "      <td>man hilari comedi stupid made realiz pil stank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>love cult 70 sci fi way like movi repo man buc...</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>lover cult sci fi way like movi repo man bucka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>amaz combin love psych two young peopl present...</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz combin lover psych two young peopl preser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>avoid one unless want watch expens bad made mo...</td>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid one unless want watch expen bad made mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>give movi break worth least 7 littl girl good ...</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>give movi break worth least littl girl good ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>gospel lou major disappoint receiv e mail thea...</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>gospel lou major disappoint receiv e mail thea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  length  polarity  \\\n",
       "0      60 background rehears record sympathi devil cl...     653         0   \n",
       "1      tess storm countri mari pickford vehicl intend...     998         1   \n",
       "2      well suppos good news concern william winckler...    1140         0   \n",
       "3      somewher read film suppos comedi see call anyt...     341         0   \n",
       "4      man hilari comedi stupid made realiz pile stan...     367         0   \n",
       "...                                                  ...     ...       ...   \n",
       "24995  love cult 70 sci fi way like movi repo man buc...     246         1   \n",
       "24996  amaz combin love psych two young peopl present...     349         1   \n",
       "24997  avoid one unless want watch expens bad made mo...     396         0   \n",
       "24998  give movi break worth least 7 littl girl good ...     136         1   \n",
       "24999  gospel lou major disappoint receiv e mail thea...     427         0   \n",
       "\n",
       "                                              clean_text  \n",
       "0      background rehear record sympathi devil classi...  \n",
       "1      tess storm countri mari pickford vehicl intend...  \n",
       "2      well suppos good news concern william winckler...  \n",
       "3      somewher read film suppos comedi see call anyt...  \n",
       "4      man hilari comedi stupid made realiz pil stank...  \n",
       "...                                                  ...  \n",
       "24995  lover cult sci fi way like movi repo man bucka...  \n",
       "24996  amaz combin lover psych two young peopl preser...  \n",
       "24997  avoid one unless want watch expen bad made mov...  \n",
       "24998  give movi break worth least littl girl good ac...  \n",
       "24999  gospel lou major disappoint receiv e mail thea...  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st step of the pipeline \n",
    "\n",
    "import spacy \n",
    "import re \n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "def clean_text (text):\n",
    "    # Minuscule\n",
    "    text = text.lower()\n",
    "    # Supprime tout sauf lettres et espaces\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ÿ\\s]\", \"\", text)\n",
    "    # Supprime les chiffres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Supprime espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    # Tokenisation + lemmatisation\n",
    "    doc = nlp(text)\n",
    "    # Renvoir la forme canonique du mot dans notre texte si ce n'est pas un stop words\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "    \n",
    "data['clean_text'] = data['text'].apply(clean_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "771f2948-e8d8-408a-939f-d9fdb4ef4807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>background rehear record sympathi devil classi...</td>\n",
       "      <td>0</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tess storm countri mari pickford vehicl intend...</td>\n",
       "      <td>1</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well suppos good news concern william winckler...</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somewher read film suppos comedi see call anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man hilari comedi stupid made realiz pil stank...</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>lover cult sci fi way like movi repo man bucka...</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>amaz combin lover psych two young peopl preser...</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>avoid one unless want watch expen bad made mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>give movi break worth least littl girl good ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>gospel lou major disappoint receiv e mail thea...</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  polarity  length\n",
       "0      background rehear record sympathi devil classi...         0     645\n",
       "1      tess storm countri mari pickford vehicl intend...         1     962\n",
       "2      well suppos good news concern william winckler...         0    1117\n",
       "3      somewher read film suppos comedi see call anyt...         0     339\n",
       "4      man hilari comedi stupid made realiz pil stank...         0     363\n",
       "...                                                  ...       ...     ...\n",
       "24995  lover cult sci fi way like movi repo man bucka...         1     238\n",
       "24996  amaz combin lover psych two young peopl preser...         1     349\n",
       "24997  avoid one unless want watch expen bad made mov...         0     394\n",
       "24998  give movi break worth least littl girl good ac...         1     133\n",
       "24999  gospel lou major disappoint receiv e mail thea...         0     423\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['clean_text', 'polarity']\n",
    "data_final = data.loc[:,columns]\n",
    "data_final.rename(columns = {'clean_text':'text'}, inplace=True)\n",
    "data_final['length'] = data_final['text'].str.len()\n",
    "data_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd9d365-5f86-463a-82f1-3604874be2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape TF-IDF only : (25000, 1551744)\n",
      "Shape final (TF-IDF + numeric) : (25000, 1551745)\n"
     ]
    }
   ],
   "source": [
    "# 2nd step of the pipeline \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_text = vectorizer.fit_transform(data_final[\"text\"])\n",
    "\n",
    "# Exemple de colonne numérique (ex: longueur du texte)\n",
    "\n",
    "#Substitution de la création de la colonne length \n",
    "X_num = data_final[\"text\"].str.len().values.reshape(-1, 1)\n",
    "\n",
    "# Concaténer TF-IDF + feature numérique\n",
    "X = hstack([X_text, X_num])\n",
    "\n",
    "# Target\n",
    "y = data_final[\"polarity\"]\n",
    "\n",
    "print(\"Shape TF-IDF only :\", X_text.shape)\n",
    "print(\"Shape final (TF-IDF + numeric) :\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "843b4edb-9448-41ca-b487-e0476ac6883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score : 0.8871885422797724\n",
      "AUC : 0.9559886239544958\n"
     ]
    }
   ],
   "source": [
    "# Our data is ready to be implement with different ML Models \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrainement du modèle \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction avec notre modèle \n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1] # Les classes positives \n",
    "\n",
    "# Evaluation du modèle \n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print (\"f1_score :\",f1)\n",
    "print(\"AUC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ee4910-8fd3-453d-986f-9698c977280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.861\n",
      "AUC: 0.938\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      2505\n",
      "           1       0.86      0.86      0.86      2495\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Séparer features & target\n",
    "X = data_final[[\"text\"]]\n",
    "y = data_final[\"polarity\"]\n",
    "\n",
    "# Fonction pour calculer la longueur de texte\n",
    "def text_length(col):\n",
    "    return col.str.len().to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Préprocessing : TF-IDF + longueur de texte\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "length_transformer = FunctionTransformer(text_length, validate=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", tfidf, \"text\"),\n",
    "        (\"length\", length_transformer, \"text\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline : prétraitement + Random Forest\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=200,    # nombre d’arbres\n",
    "        max_depth=None,      # profondeur max (None = auto)\n",
    "        random_state=42,\n",
    "        n_jobs=-1            # parallélisation\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"F1-score:\", round(f1, 3))\n",
    "print(\"AUC:\", round(auc, 3))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50649b54-5aa4-4886-9fd5-09cc18cf4e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describ larri interview complet suckhol everi ...</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>describ larri interview complet suckhol everi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giorgino peopl look bit long one rare real rom...</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>giorgino peopl look bit long one rare real rom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movi amaz never seen film brought harsh realit...</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>movi amaz never seen film brought harsh realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one anim film animatrix collect one nine one d...</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>one anim film animatrix collect one nine one d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juli andrew satir prod goodi two shoe imag ove...</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>juli andrew satir production goodi two shoe im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>guess leonard nimoy success direct search spoc...</td>\n",
       "      <td>2723</td>\n",
       "      <td>0</td>\n",
       "      <td>guess leonard nimoy success direct search spoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>karim hussain masterpiec art gore cat definit ...</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>karim hussain masterpiec art gore cat definit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>film infantri das boot submarin appreci das bo...</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>film infantri das boot submarin appreci das bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>absolut love movi great realist look combat fo...</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>absolut lover movi great realist look combat f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>last film krzysztof kieslowski one greatest di...</td>\n",
       "      <td>990</td>\n",
       "      <td>1</td>\n",
       "      <td>last film krzysztof kieslowski one greatest di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  length  polarity  \\\n",
       "0      describ larri interview complet suckhol everi ...     458         0   \n",
       "1      giorgino peopl look bit long one rare real rom...     113         1   \n",
       "2      movi amaz never seen film brought harsh realit...     218         1   \n",
       "3      one anim film animatrix collect one nine one d...     191         1   \n",
       "4      juli andrew satir prod goodi two shoe imag ove...     713         0   \n",
       "...                                                  ...     ...       ...   \n",
       "24995  guess leonard nimoy success direct search spoc...    2723         0   \n",
       "24996  karim hussain masterpiec art gore cat definit ...    1273         1   \n",
       "24997  film infantri das boot submarin appreci das bo...     392         1   \n",
       "24998  absolut love movi great realist look combat fo...     491         1   \n",
       "24999  last film krzysztof kieslowski one greatest di...     990         1   \n",
       "\n",
       "                                              clean_text  \n",
       "0      describ larri interview complet suckhol everi ...  \n",
       "1      giorgino peopl look bit long one rare real rom...  \n",
       "2      movi amaz never seen film brought harsh realit...  \n",
       "3      one anim film animatrix collect one nine one d...  \n",
       "4      juli andrew satir production goodi two shoe im...  \n",
       "...                                                  ...  \n",
       "24995  guess leonard nimoy success direct search spoc...  \n",
       "24996  karim hussain masterpiec art gore cat definit ...  \n",
       "24997  film infantri das boot submarin appreci das bo...  \n",
       "24998  absolut lover movi great realist look combat f...  \n",
       "24999  last film krzysztof kieslowski one greatest di...  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "import re \n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "def clean_text (text):\n",
    "    # Minuscule\n",
    "    text = text.lower()\n",
    "    # Supprime tout sauf lettres et espaces\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ÿ\\s]\", \"\", text)\n",
    "    # Supprime les chiffres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Supprime espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    # Tokenisation + lemmatisation\n",
    "    doc = nlp(text)\n",
    "    # Renvoir la forme canonique du mot dans notre texte si ce n'est pas un stop words\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "    \n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d81e90b-c5a0-40d7-9499-d5704ae32696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>describ larri interview complet suckhol everi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>giorgino peopl look bit long one rare real rom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>movi amaz never seen film brought harsh realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>one anim film animatrix collect one nine one d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>juli andrew satir production goodi two shoe im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>guess leonard nimoy success direct search spoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>karim hussain masterpiec art gore cat definit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "      <td>film infantri das boot submarin appreci das bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>absolut lover movi great realist look combat f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "      <td>last film krzysztof kieslowski one greatest di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                         clean_text\n",
       "0             0  describ larri interview complet suckhol everi ...\n",
       "1             1  giorgino peopl look bit long one rare real rom...\n",
       "2             1  movi amaz never seen film brought harsh realit...\n",
       "3             1  one anim film animatrix collect one nine one d...\n",
       "4             0  juli andrew satir production goodi two shoe im...\n",
       "...         ...                                                ...\n",
       "24995         0  guess leonard nimoy success direct search spoc...\n",
       "24996         1  karim hussain masterpiec art gore cat definit ...\n",
       "24997         1  film infantri das boot submarin appreci das bo...\n",
       "24998         1  absolut lover movi great realist look combat f...\n",
       "24999         1  last film krzysztof kieslowski one greatest di...\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('length', axis = 1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2728bdd8-24e2-4962-bc41-6893d4daabb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>describ larri interview complet suckhol everi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>giorgino peopl look bit long one rare real rom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>movi amaz never seen film brought harsh realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>one anim film animatrix collect one nine one d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>juli andrew satir production goodi two shoe im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>guess leonard nimoy success direct search spoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>karim hussain masterpiec art gore cat definit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "      <td>film infantri das boot submarin appreci das bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>absolut lover movi great realist look combat f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "      <td>last film krzysztof kieslowski one greatest di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                               text\n",
       "0             0  describ larri interview complet suckhol everi ...\n",
       "1             1  giorgino peopl look bit long one rare real rom...\n",
       "2             1  movi amaz never seen film brought harsh realit...\n",
       "3             1  one anim film animatrix collect one nine one d...\n",
       "4             0  juli andrew satir production goodi two shoe im...\n",
       "...         ...                                                ...\n",
       "24995         0  guess leonard nimoy success direct search spoc...\n",
       "24996         1  karim hussain masterpiec art gore cat definit ...\n",
       "24997         1  film infantri das boot submarin appreci das bo...\n",
       "24998         1  absolut lover movi great realist look combat f...\n",
       "24999         1  last film krzysztof kieslowski one greatest di...\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {'clean_text' : 'text'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "576fc6bd-9c98-4da2-9cd1-977e20388f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape TF-IDF only : (25000, 1551744)\n",
      "Shape final (TF-IDF + numeric) : (25000, 1551745)\n"
     ]
    }
   ],
   "source": [
    "# 2nd step of the pipeline \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_text = vectorizer.fit_transform(data_final[\"text\"])\n",
    "\n",
    "# Exemple de colonne numérique (ex: longueur du texte)\n",
    "\n",
    "#Substitution de la création de la colonne length \n",
    "X_num = df[\"text\"].str.len().values.reshape(-1, 1)\n",
    "\n",
    "# Concaténer TF-IDF + feature numérique\n",
    "X = hstack([X_text, X_num])\n",
    "\n",
    "# Target\n",
    "y = df[\"polarity\"]\n",
    "\n",
    "print(\"Shape TF-IDF only :\", X_text.shape)\n",
    "print(\"Shape final (TF-IDF + numeric) :\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d7bb161-4150-4d35-91ee-06c4416c965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score : 0.5017906884202149\n",
      "AUC : 0.5030248174229484\n"
     ]
    }
   ],
   "source": [
    "# Our data is ready to be implement with different ML Models \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrainement du modèle \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction avec notre modèle \n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1] # Les classes positives \n",
    "\n",
    "# Evaluation du modèle \n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print (\"f1_score :\",f1)\n",
    "print(\"AUC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "855468d9-fb31-4c80-906b-498520b87ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.873\n",
      "AUC: 0.946\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      2506\n",
      "           1       0.88      0.87      0.87      2494\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Séparer features & target\n",
    "X = df[[\"text\"]]\n",
    "y = df[\"polarity\"]\n",
    "\n",
    "# Fonction pour calculer la longueur de texte\n",
    "def text_length(col):\n",
    "    return col.str.len().to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Préprocessing : TF-IDF + longueur de texte\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "length_transformer = FunctionTransformer(text_length, validate=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", tfidf, \"text\"),\n",
    "        (\"length\", length_transformer, \"text\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline : prétraitement + Random Forest\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=200,    # nombre d’arbres\n",
    "        max_depth=None,      # profondeur max (None = auto)\n",
    "        random_state=42,\n",
    "        n_jobs=-1            # parallélisation\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"F1-score:\", round(f1, 3))\n",
    "print(\"AUC:\", round(auc, 3))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f27691e-9825-44db-bfd2-94bbc9838e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/j7skd__n5c7f0c9l6nfx71f00000gn/T/ipykernel_60015/192136432.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['proba_1'] = y_proba\n",
      "/var/folders/3y/j7skd__n5c7f0c9l6nfx71f00000gn/T/ipykernel_60015/192136432.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['proba_0'] = pipeline.predict_proba(X_test)[:, 0]\n",
      "/var/folders/3y/j7skd__n5c7f0c9l6nfx71f00000gn/T/ipykernel_60015/192136432.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['prediction'] = y_pred\n",
      "/var/folders/3y/j7skd__n5c7f0c9l6nfx71f00000gn/T/ipykernel_60015/192136432.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['vrai prediction'] = y_test\n",
      "/var/folders/3y/j7skd__n5c7f0c9l6nfx71f00000gn/T/ipykernel_60015/192136432.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['prediction correct'] = df_test['prediction'] == df_test['vrai prediction']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>prediction</th>\n",
       "      <th>vrai prediction</th>\n",
       "      <th>prediction correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>1</td>\n",
       "      <td>hand death definit rate ten scal one devoir sm...</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24016</th>\n",
       "      <td>1</td>\n",
       "      <td>film gav probabl pleaser surprendre ever seen ...</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9668</th>\n",
       "      <td>1</td>\n",
       "      <td>although low budget film clear last minut hold...</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>0</td>\n",
       "      <td>anyon think great sport movi probabl sport mov...</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>0</td>\n",
       "      <td>t understand mani good review found photograph...</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>0</td>\n",
       "      <td>director sper lot time make scene look real ri...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11839</th>\n",
       "      <td>0</td>\n",
       "      <td>movi base jacquelin susann best sell novel rob...</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>1</td>\n",
       "      <td>read innumer review talk superior mini seri t ...</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21147</th>\n",
       "      <td>1</td>\n",
       "      <td>robin hood men tight worth watch recer watch j...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1</td>\n",
       "      <td>beatl just done magic mysteri tour general fee...</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                               text  proba_1  \\\n",
       "6868          1  hand death definit rate ten scal one devoir sm...    0.525   \n",
       "24016         1  film gav probabl pleaser surprendre ever seen ...    0.565   \n",
       "9668          1  although low budget film clear last minut hold...    0.620   \n",
       "13640         0  anyon think great sport movi probabl sport mov...    0.425   \n",
       "14018         0  t understand mani good review found photograph...    0.405   \n",
       "...         ...                                                ...      ...   \n",
       "8670          0  director sper lot time make scene look real ri...    0.300   \n",
       "11839         0  movi base jacquelin susann best sell novel rob...    0.390   \n",
       "4013          1  read innumer review talk superior mini seri t ...    0.490   \n",
       "21147         1  robin hood men tight worth watch recer watch j...    0.625   \n",
       "695           1  beatl just done magic mysteri tour general fee...    0.410   \n",
       "\n",
       "       proba_0  prediction  vrai prediction  prediction correct  \n",
       "6868     0.475           1                1                True  \n",
       "24016    0.435           1                1                True  \n",
       "9668     0.380           1                1                True  \n",
       "13640    0.575           0                0                True  \n",
       "14018    0.595           0                0                True  \n",
       "...        ...         ...              ...                 ...  \n",
       "8670     0.700           0                0                True  \n",
       "11839    0.610           0                0                True  \n",
       "4013     0.510           0                1               False  \n",
       "21147    0.375           1                1                True  \n",
       "695      0.590           0                1               False  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming X_test and y_proba are for the same subset of data\n",
    "# Make sure the DataFrame you're modifying contains only the test data\n",
    "df_test = df.iloc[X_test.index] if hasattr(X_test, 'index') else df.iloc[:len(X_test)]\n",
    "\n",
    "# Now assign probabilities to this test DataFrame\n",
    "df_test['proba_1'] = y_proba\n",
    "df_test['proba_0'] = pipeline.predict_proba(X_test)[:, 0]\n",
    "df_test['prediction'] = y_pred\n",
    "df_test['vrai prediction'] = y_test\n",
    "df_test['prediction correct'] = df_test['prediction'] == df_test['vrai prediction']\n",
    "\n",
    "# If you need to update the original DataFrame\n",
    "# df.loc[df_test.index, 'proba_1'] = y_proba\n",
    "# df.loc[df_test.index, 'proba_0'] = pipeline.predict_proba(X_test)[:, 0]\n",
    "\n",
    "df_test  # Display the test DataFrame with probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "220c7377-16d4-467c-86aa-1f2197d5151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for the product. It was exactly as desc...</td>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I saw him almost win the American Idol on whic...</td>\n",
       "      <td>Digital Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very good quality filament. Surface texture is...</td>\n",
       "      <td>Industrial and Scientific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have tried the cheaper carts and they do not...</td>\n",
       "      <td>Office Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I purchased this to sit on a shelf of a floor ...</td>\n",
       "      <td>Toys and Games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Thanks for the product. It was exactly as desc...   \n",
       "1  I saw him almost win the American Idol on whic...   \n",
       "2  Very good quality filament. Surface texture is...   \n",
       "3  I have tried the cheaper carts and they do not...   \n",
       "4  I purchased this to sit on a shelf of a floor ...   \n",
       "\n",
       "              product_category  \n",
       "0  Cell Phones and Accessories  \n",
       "1                Digital Music  \n",
       "2    Industrial and Scientific  \n",
       "3              Office Products  \n",
       "4               Toys and Games  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('product_reviews.xlsx')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e3e509d-22b2-4eec-af74-2f33585aec6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for the product. It was exactly as desc...</td>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>thanks for the product it was exactly describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I saw him almost win the American Idol on whic...</td>\n",
       "      <td>Digital Music</td>\n",
       "      <td>saw him almost win the american idol whichever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very good quality filament. Surface texture is...</td>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>very good quality filament surface textur is e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have tried the cheaper carts and they do not...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>haver tried the cheaper cart and they do not d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I purchased this to sit on a shelf of a floor ...</td>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>purchased this to sit shelf of floor lamp to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Truck shell was cracked upon arrival\\nThe susp...</td>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>truck shell was cracked upon arrival the suspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not bad but super not durable! After only a co...</td>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>not bad but super not durable after only coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These are basically crap..... Not ONE of them ...</td>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>these are basically crap not one of them actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synth beats, smoking weed, beetches, sampling....</td>\n",
       "      <td>Digital Music</td>\n",
       "      <td>synth beats smoking weed beetches sampling was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like all the versions - but be careful - not f...</td>\n",
       "      <td>Digital Music</td>\n",
       "      <td>like all the version but be careful not for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A nice alternative to spending more money at t...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>nice alternatif to spending more money at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>With the constant changes in connections this ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>with the constant change in connexion this lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>excellent product.  I especially like the feat...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>excellent product especially like the feature ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The magnetic attachment is much more convenien...</td>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>the magnetic attachment is much more convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I bought these bearings as replacements for th...</td>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>bought these bearings replacement for the ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I make sure I have one of these at every job I...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>make sur haver one of these at every job go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>this is perfect for what i needed! its thin co...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>this is perfect for what needed its thin cork ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>just what we expected to protect our computer ...</td>\n",
       "      <td>Software</td>\n",
       "      <td>just what we expected to protect our computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Don't know know I ever got by without it. 10 p...</td>\n",
       "      <td>Software</td>\n",
       "      <td>know know ever got by without it years but wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I wasn't a fan of the ribbon when MS first int...</td>\n",
       "      <td>Software</td>\n",
       "      <td>wasnt fan of the ribbon when ms first introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I was very disappointed in this.  The elephant...</td>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>was very disappointed in this the elephant pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Thanks for the product. It was exactly as desc...   \n",
       "1   I saw him almost win the American Idol on whic...   \n",
       "2   Very good quality filament. Surface texture is...   \n",
       "3   I have tried the cheaper carts and they do not...   \n",
       "4   I purchased this to sit on a shelf of a floor ...   \n",
       "5   Truck shell was cracked upon arrival\\nThe susp...   \n",
       "6   Not bad but super not durable! After only a co...   \n",
       "7   These are basically crap..... Not ONE of them ...   \n",
       "8   Synth beats, smoking weed, beetches, sampling....   \n",
       "9   like all the versions - but be careful - not f...   \n",
       "10  A nice alternative to spending more money at t...   \n",
       "11  With the constant changes in connections this ...   \n",
       "12  excellent product.  I especially like the feat...   \n",
       "13  The magnetic attachment is much more convenien...   \n",
       "14  I bought these bearings as replacements for th...   \n",
       "15  I make sure I have one of these at every job I...   \n",
       "16  this is perfect for what i needed! its thin co...   \n",
       "17  just what we expected to protect our computer ...   \n",
       "18  Don't know know I ever got by without it. 10 p...   \n",
       "19  I wasn't a fan of the ribbon when MS first int...   \n",
       "20  I was very disappointed in this.  The elephant...   \n",
       "\n",
       "               product_category  \\\n",
       "0   Cell Phones and Accessories   \n",
       "1                 Digital Music   \n",
       "2     Industrial and Scientific   \n",
       "3               Office Products   \n",
       "4                Toys and Games   \n",
       "5                Toys and Games   \n",
       "6   Cell Phones and Accessories   \n",
       "7   Cell Phones and Accessories   \n",
       "8                 Digital Music   \n",
       "9                 Digital Music   \n",
       "10                  Electronics   \n",
       "11                  Electronics   \n",
       "12                  Electronics   \n",
       "13    Industrial and Scientific   \n",
       "14    Industrial and Scientific   \n",
       "15              Office Products   \n",
       "16              Office Products   \n",
       "17                     Software   \n",
       "18                     Software   \n",
       "19                     Software   \n",
       "20               Toys and Games   \n",
       "\n",
       "                                           clean_text  \n",
       "0   thanks for the product it was exactly describe...  \n",
       "1   saw him almost win the american idol whichever...  \n",
       "2   very good quality filament surface textur is e...  \n",
       "3   haver tried the cheaper cart and they do not d...  \n",
       "4   purchased this to sit shelf of floor lamp to c...  \n",
       "5   truck shell was cracked upon arrival the suspe...  \n",
       "6   not bad but super not durable after only coupl...  \n",
       "7   these are basically crap not one of them actua...  \n",
       "8   synth beats smoking weed beetches sampling was...  \n",
       "9   like all the version but be careful not for yo...  \n",
       "10  nice alternatif to spending more money at the ...  \n",
       "11  with the constant change in connexion this lit...  \n",
       "12  excellent product especially like the feature ...  \n",
       "13  the magnetic attachment is much more convenien...  \n",
       "14  bought these bearings replacement for the ones...  \n",
       "15  make sur haver one of these at every job go to...  \n",
       "16  this is perfect for what needed its thin cork ...  \n",
       "17  just what we expected to protect our computer ...  \n",
       "18  know know ever got by without it years but wis...  \n",
       "19  wasnt fan of the ribbon when ms first introduc...  \n",
       "20  was very disappointed in this the elephant pla...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "import re \n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "def clean_text (text):\n",
    "    # Minuscule\n",
    "    text = text.lower()\n",
    "    # Supprime tout sauf lettres et espaces\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ÿ\\s]\", \"\", text)\n",
    "    # Supprime les chiffres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Supprime espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    # Tokenisation + lemmatisation\n",
    "    doc = nlp(text)\n",
    "    # Renvoir la forme canonique du mot dans notre texte si ce n'est pas un stop words\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "    \n",
    "df1['clean_text'] = df1['text'].apply(clean_text)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58b1f3c1-87a6-4484-b006-974564fd2af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>thanks for the product it was exactly describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital Music</td>\n",
       "      <td>saw him almost win the american idol whichever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>very good quality filament surface textur is e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office Products</td>\n",
       "      <td>haver tried the cheaper cart and they do not d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>purchased this to sit shelf of floor lamp to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>truck shell was cracked upon arrival the suspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>not bad but super not durable after only coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cell Phones and Accessories</td>\n",
       "      <td>these are basically crap not one of them actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Digital Music</td>\n",
       "      <td>synth beats smoking weed beetches sampling was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Digital Music</td>\n",
       "      <td>like all the version but be careful not for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>nice alternatif to spending more money at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>with the constant change in connexion this lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>excellent product especially like the feature ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>the magnetic attachment is much more convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Industrial and Scientific</td>\n",
       "      <td>bought these bearings replacement for the ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Office Products</td>\n",
       "      <td>make sur haver one of these at every job go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Office Products</td>\n",
       "      <td>this is perfect for what needed its thin cork ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Software</td>\n",
       "      <td>just what we expected to protect our computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Software</td>\n",
       "      <td>know know ever got by without it years but wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Software</td>\n",
       "      <td>wasnt fan of the ribbon when ms first introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toys and Games</td>\n",
       "      <td>was very disappointed in this the elephant pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               product_category  \\\n",
       "0   Cell Phones and Accessories   \n",
       "1                 Digital Music   \n",
       "2     Industrial and Scientific   \n",
       "3               Office Products   \n",
       "4                Toys and Games   \n",
       "5                Toys and Games   \n",
       "6   Cell Phones and Accessories   \n",
       "7   Cell Phones and Accessories   \n",
       "8                 Digital Music   \n",
       "9                 Digital Music   \n",
       "10                  Electronics   \n",
       "11                  Electronics   \n",
       "12                  Electronics   \n",
       "13    Industrial and Scientific   \n",
       "14    Industrial and Scientific   \n",
       "15              Office Products   \n",
       "16              Office Products   \n",
       "17                     Software   \n",
       "18                     Software   \n",
       "19                     Software   \n",
       "20               Toys and Games   \n",
       "\n",
       "                                                 text  \n",
       "0   thanks for the product it was exactly describe...  \n",
       "1   saw him almost win the american idol whichever...  \n",
       "2   very good quality filament surface textur is e...  \n",
       "3   haver tried the cheaper cart and they do not d...  \n",
       "4   purchased this to sit shelf of floor lamp to c...  \n",
       "5   truck shell was cracked upon arrival the suspe...  \n",
       "6   not bad but super not durable after only coupl...  \n",
       "7   these are basically crap not one of them actua...  \n",
       "8   synth beats smoking weed beetches sampling was...  \n",
       "9   like all the version but be careful not for yo...  \n",
       "10  nice alternatif to spending more money at the ...  \n",
       "11  with the constant change in connexion this lit...  \n",
       "12  excellent product especially like the feature ...  \n",
       "13  the magnetic attachment is much more convenien...  \n",
       "14  bought these bearings replacement for the ones...  \n",
       "15  make sur haver one of these at every job go to...  \n",
       "16  this is perfect for what needed its thin cork ...  \n",
       "17  just what we expected to protect our computer ...  \n",
       "18  know know ever got by without it years but wis...  \n",
       "19  wasnt fan of the ribbon when ms first introduc...  \n",
       "20  was very disappointed in this the elephant pla...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.rename(columns = {'clean_text' : 'text'}, inplace=True )\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aef63-bf81-4612-9a6a-ecfdeca654ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
